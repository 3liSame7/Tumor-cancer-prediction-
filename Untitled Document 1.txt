import pandas as pd
import voting as voting
from sklearn import ensemble
# from sklearn.feature_extraction.text import CountVectorizer
import estimators as estimators
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
report_logistic_regression(X_test, Y_test)
from sklearn.metrics import accuracy_score

# report_svm(X_test, Y_test)

# predict = pd.DataFrame(predict,
#                        columns=['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13',
#                                 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23', 'F24', 'F25',
#                                 'F26', 'F27', 'F28', 'F29', 'F30'])


# [0.01666, 14.22, 23.12, 94.37, 0.05113, 0.1075, 0.1533, 0.2413, 0.1981, 0.1166, 0.06618, 0.1354, 0.1446, 0.2384,
# 0.07542, 762.4, 0.286, 0.5166, 0.9327, 2.11, 2.112, 31.72, 0.00797, 0.8488, 0.01172, 15.74, 37.18, 106.4, 609.9,
# 0.1772]>>>>1
#
#
# [0.01843, 11.8, 16.58, 78.99, 0.05628, 0.1091, 0.1385, 0.17, 0.1659, 0.04649, 0.07415, 0.03633, 0.103,
# 0.2678, 0.07371, 591.7, 0.3197, 0.5774, 0.4092, 1.426, 2.281, 24.72, 0.005427, 0.4504, 0.004635, 13.74, 26.38,
# 91.93, 432, 0.1865]>>>>>1
#
# [0.009924, 11.37, 18.89, 72.17, 0.03416, 0.08713, 0.1118, 0.05008, 0.02399, 0.01376, 0.02173,
# 0.01395, 0.06994, 0.2013, 0.05955, 459.3, 0.2656, 0.3267, 0.09708, 1.974, 1.954, 17.49, 0.006538, 0.07529,
# 0.002928, 12.36, 26.14, 79.29, 396, 0.06203] >>>0>>>188


# [0.009924, 11.37, 18.89, 72.17, 0.03416, 0.08713, 0.1118, 0.05008, 0.02399, 0.01376, 0.02173, 0.01395, 0.06994,
# 0.2013, 0.05955, 459.3, 0.2656, 0.3267, 0.09708, 1.974, 1.954, 17.49, 0.006538, 0.07529, 0.002928, 12.36, 26.14,
# 79.29, 396, 0.06203]>>>1>>>9

# 0.009924 11.37 18.89 72.17 0.03416 0.08713 0.1118 0.05008 0.02399 0.01376 0.02173 0.01395 0.06994 0.2013 0.05955 459.3 0.2656 0.3267 0.09708 1.974 1.954 17.49 0.006538 0.07529 0.002928 12.36 26.14 79.29 396 0.06203

# 0.01339	11.08	18.83	73.3	0.01738	0.1216	0.2184	0.2154	0.1689	0.04588	0.06367	0.04549	0.1403	0.2196	0.0795	508.1	0.2114	0.4154	0.9379	1.027	1.719	13.99	0.007405	0.8402	0.004435	13.24	32.82	91.76	361.6	0.2524
# >>1

# 0.01648	18.01	20.56	118.4	0.02897	0.1001	0.1309	0.1289	0.117	0.03737	0.07762	0.027	0.07625	0.2116	0.06077	1426	0.7548	0.3251	0.2327	1.288	5.353	89.74	0.007997	0.2544	0.003996	21.53	26.06	143.4	1007	0.1489
# 1

# 0.01774	12.89	15.7	84.08	0.01878	0.07818	0.09926	0.0958	0.1115	0.07927	0.0339	0.03961	0.07127	0.1432	0.05935	595.6	0.2913	0.1999	0.2317	1.389	2.347	23.29	0.006418	0.3344	0.003696	13.9	19.69	92.12	516.6	0.1017
# 0

# 0.003762	12.42	15.04	78.61	0.0172	0.07926	0.1037	0.03393	0.01053	0.006493	0.01108	0.00493	0.06783	0.1546	0.05754	543.4	0.1153	0.2901	0.07776	0.6745	0.757	9.006	0.003265	0.06243	0.00136	13.2	20.37	83.85	476.5	0.04052
# 0

# 0.01087	12.21	14.09	78.78	0.01921	0.08108	0.1026	0.07823	0.06839	0.04344	0.02534	0.03026	0.08824	0.1646	0.06154	529.9	0.2666	0.2677	0.2431	0.8309	2.097	19.96	0.004405	0.3076	0.004622	13.13	19.29	87.65	462	0.0914
# 0

# 0.01846	11.74	14.02	74.24	0.02921	0.07813	0.1036	0.0434	0.02245	0.01514	0.02763	0.01442	0.06688	0.2101	0.06113	533.7	0.5619	0.3101	0.085	1.268	3.717	37.83	0.008034	0.06735	0.002005	13.31	18.26	84.7	427.3	0.0829
# 0


# drop outliers
# Q1 = data.quantile(0.05)
# Q3 = data.quantile(0.95)
#
# IQR = Q3 - Q1
#
# Lower = Q1 - 1.5 * IQR
# Upper = Q3 + 1.5 * IQR

# data = data[(data.iloc[:, 0:30] > Lower) & (data.iloc[:, 0:30] < Upper)]
#
# corpus = data
# Vectorizer = CountVectorizer()
# data = Vectorizer.fit_transform(corpus)
# data = pd.DataFrame(data.todense())
# corpus = a
# corpus = [str(item) for item in corpus]
# Vectorizer = CountVectorizer()
# a = Vectorizer.fit_132	0.01339	11.08	18.83	73.3	0.01738	0.1216	0.2184	0.2154	0.1689	0.04588	0.06367	0.04549	0.1403	0.2196	0.0795	508.1	0.2114	0.4154	0.9379	1.027	1.719	13.99	0.007405	0.8402	0.004435	13.24	32.82	91.76	361.6	0.2524	M
# transform(corpus)
# a = pd.DataFrame(a.todense())
# print(data.isna().sum())
# print(data['diagnosis'].value_counts())
# x = [0.009924, 11.37, 18.89, 72.17, 0.03416, 0.08713, 0.1118, 0.05008, 0.02399, 0.01376, 0.02173, 0.01395, 0.06994,
# # 0.2013, 0.05955, 459.3, 0.2656, 0.3267, 0.09708, 1.974, 1.954, 17.49, 0.006538, 0.07529, 0.002928, 12.36, 26.14,
# # 79.29, 396, 0.06203]

# 0.01846	11.74	14.02	74.24	0.02921	0.07813	0.1036	0.0434	0.02245	0.01514	0.02763	0.01442	0.06688	0.2101	0.06113	533.7	0.5619	0.3101	0.085	1.268	3.717	37.83	0.008034	0.06735	0.002005	13.31	18.26	84.7	427.3	0.0829
# 0


#
# def scaling_data(data_sc, choose):
#     # Scaling data
#     if choose == '1':
#         scaling = StandardScaler()
#         data_sc = pd.DataFrame(scaling.fit_transform(data_sc))
#
#     elif choose == '2':
#         print(data_sc.head(8))
#         scaling = MinMaxScaler()
#         data_sc = pd.DataFrame(scaling.fit_transform(data_sc))
#         print(data_sc.head(8))
#
#     else:
#         print("Error")
#         return 1
#
#     return data_sc

